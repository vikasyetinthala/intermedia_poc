{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Invoice Classification System (Advanced)\n",
    "\n",
    "This notebook implements an enterprise-grade ML system to classify invoices.\n",
    "\n",
    "**Key Improvements**:\n",
    "- **Realistic Data Ingestion**: Handles Currency, Requestors, and Descriptions.\n",
    "- **Smart Matching**: Fuzzy logic on amounts and dates.\n",
    "- **Advanced Feature Engineering**:\n",
    "    - **Supplier Behavior**: Tenure, Risk Score, Historical Approval Rate.\n",
    "    - **PO Variance**: Amount, Currency Mismatch, Description Similarity.\n",
    "    - **Text Analysis**: TF-IDF Vectorization -> SVD (Latent Semantic Analysis) for description features.\n",
    "- **Gemini Integration**: Explains the top risk factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Configured.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load Env\n",
    "load_dotenv('.env')\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "if GEMINI_API_KEY:\n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "    print(\"Gemini Configured.\")\n",
    "else:\n",
    "    print(\"Gemini API Key missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion & Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded.\n"
     ]
    }
   ],
   "source": [
    "base_path = \"dataset/\"\n",
    "suppliers = pd.read_csv(f\"{base_path}suppliers.csv\")\n",
    "pos = pd.read_csv(f\"{base_path}purchase_orders.csv\")\n",
    "history = pd.read_csv(f\"{base_path}invoices_history.csv\")\n",
    "new_invoices = pd.read_csv(f\"{base_path}invoices_new.csv\")\n",
    "\n",
    "# Pre-calculate Supplier Approval History (Simulating historical knowledge)\n",
    "# In a real system, this would be an aggregation of PAST invoices only.\n",
    "# For this demo, we use the training set to build a lookup.\n",
    "supplier_stats = history.groupby('Supplier_ID')['Status'].apply(lambda x: (x == 'Approve').mean()).reset_index()\n",
    "supplier_stats.columns = ['Supplier_ID', 'Supplier_Approval_Rate']\n",
    "suppliers = suppliers.merge(supplier_stats, on='Supplier_ID', how='left').fillna(0.5)\n",
    "\n",
    "print(\"Data Loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced PO Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_po(inv_row, pos_df):\n",
    "    # 1. Strict\n",
    "    if pd.notna(inv_row['PO_Number']) and inv_row['PO_Number'] != \"\":\n",
    "        match = pos_df[pos_df['PO_Number'] == inv_row['PO_Number']]\n",
    "        if not match.empty:\n",
    "            return match.iloc[0], \"Strict\"\n",
    "            \n",
    "    # 2. Smart (Supplier + Amount +/- 2%)\n",
    "    candidates = pos_df[pos_df['Supplier_ID'] == inv_row['Supplier_ID']]\n",
    "    if not candidates.empty:\n",
    "        candidates = candidates.copy()\n",
    "        candidates['Diff'] = abs(candidates['PO_Amount'] - inv_row['Invoice_Amount']) / candidates['PO_Amount']\n",
    "        best = candidates[candidates['Diff'] < 0.02].sort_values('Diff').head(1)\n",
    "        if not best.empty:\n",
    "            return best.iloc[0], \"Smart\"\n",
    "            \n",
    "    return None, \"None\"\n",
    "\n",
    "def enrich_data(invoices, pos_df, suppliers_df):\n",
    "    enriched = []\n",
    "    for _, row in invoices.iterrows():\n",
    "        po, match_type = match_po(row, pos_df)\n",
    "        d = row.to_dict()\n",
    "        d['Match_Type'] = match_type\n",
    "        \n",
    "        if po is not None:\n",
    "            d['PO_Amount'] = po['PO_Amount']\n",
    "            d['PO_Currency'] = po['Currency']\n",
    "            d['PO_Date'] = po['PO_Date']\n",
    "            d['PO_Desc'] = po['Description']\n",
    "        else:\n",
    "            d['PO_Amount'] = 0\n",
    "            d['PO_Currency'] = \"UNK\"\n",
    "            d['PO_Date'] = None\n",
    "            d['PO_Desc'] = \"\"\n",
    "            \n",
    "        # Supplier Meta\n",
    "        sup = suppliers_df[suppliers_df['Supplier_ID'] == row['Supplier_ID']]\n",
    "        if not sup.empty:\n",
    "            d['Sup_Risk'] = sup.iloc[0]['Risk_Score']\n",
    "            d['Sup_Tenure'] = sup.iloc[0]['Tenure_Days']\n",
    "            d['Sup_Approval_Rate'] = sup.iloc[0]['Supplier_Approval_Rate']\n",
    "        else:\n",
    "            d['Sup_Risk'] = 50\n",
    "            d['Sup_Tenure'] = 0\n",
    "            d['Sup_Approval_Rate'] = 0.5\n",
    "            \n",
    "        enriched.append(d)\n",
    "    return pd.DataFrame(enriched)\n",
    "\n",
    "df_train_raw = enrich_data(history, pos, suppliers)\n",
    "df_new_raw = enrich_data(new_invoices, pos, suppliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Analysis (TF-IDF + SVD)\n",
    "We convert descriptions into dense numerical vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Analysis Complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Vectorizer and SVD\n",
    "tfidf = TfidfVectorizer(max_features=500, stop_words='english')\n",
    "svd = TruncatedSVD(n_components=5, random_state=42) # Reduce text to 5 features\n",
    "\n",
    "# Fit on Training Descriptions\n",
    "text_train = df_train_raw['Description'].fillna(\"\")\n",
    "tfidf_matrix = tfidf.fit_transform(text_train)\n",
    "svd_features = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Create DataFrame for Text Features\n",
    "text_cols = [f'Text_SVD_{i}' for i in range(5)]\n",
    "df_text_features = pd.DataFrame(svd_features, columns=text_cols)\n",
    "df_train_raw = pd.concat([df_train_raw, df_text_features], axis=1)\n",
    "\n",
    "# Transform New Data using same pipeline\n",
    "text_new = df_new_raw['Description'].fillna(\"\")\n",
    "tfidf_new = tfidf.transform(text_new)\n",
    "svd_new = svd.transform(tfidf_new)\n",
    "df_text_new = pd.DataFrame(svd_new, columns=text_cols)\n",
    "df_new_raw = pd.concat([df_new_raw, df_text_new], axis=1)\n",
    "\n",
    "print(\"Text Analysis Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comprehensive Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineered_features(df):\n",
    "    # Variance\n",
    "    df['Amt_Variance'] = np.where(df['PO_Amount'] > 0, (df['Invoice_Amount'] - df['PO_Amount'])/df['PO_Amount'], 0)\n",
    "    df['Currency_Mismatch'] = (df['Currency'] != df['PO_Currency']).astype(int)\n",
    "    \n",
    "    # Date Variance\n",
    "    df['Invoice_Date'] = pd.to_datetime(df['Invoice_Date'])\n",
    "    df['PO_Date'] = pd.to_datetime(df['PO_Date'])\n",
    "    df['Days_Since_PO'] = (df['Invoice_Date'] - df['PO_Date']).dt.days.fillna(-1)\n",
    "    \n",
    "    # Categorical Encoding\n",
    "    le = LabelEncoder()\n",
    "    df['Dept_Code'] = le.fit_transform(df['Department'].astype(str))\n",
    "    df['Requestor_Code'] = le.fit_transform(df['Requestor'].astype(str))\n",
    "    df['Match_Type_Code'] = le.fit_transform(df['Match_Type'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features ready: ['Invoice_Amount', 'Sup_Risk', 'Sup_Tenure', 'Sup_Approval_Rate', 'Amt_Variance', 'Currency_Mismatch', 'Days_Since_PO', 'Dept_Code', 'Match_Type_Code', 'Text_SVD_0', 'Text_SVD_1', 'Text_SVD_2', 'Text_SVD_3', 'Text_SVD_4']\n"
     ]
    }
   ],
   "source": [
    "df_train_final = engineered_features(df_train_raw)\n",
    "df_new_final = engineered_features(df_new_raw)\n",
    "\n",
    "features = ['Invoice_Amount', 'Sup_Risk', 'Sup_Tenure', 'Sup_Approval_Rate',\n",
    "            'Amt_Variance', 'Currency_Mismatch', 'Days_Since_PO', \n",
    "            'Dept_Code', 'Match_Type_Code'] + text_cols\n",
    "\n",
    "print(\"Features ready:\", features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1001\n",
      "[LightGBM] [Info] Number of data points in the train set: 1200, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -0.492931\n",
      "[LightGBM] [Info] Start training from score -1.728785\n",
      "[LightGBM] [Info] Start training from score -1.552743\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       Approve       0.99      1.00      1.00       179\n",
      "        Reject       1.00      0.91      0.95        57\n",
      "Review Further       0.94      1.00      0.97        64\n",
      "\n",
      "      accuracy                           0.98       300\n",
      "     macro avg       0.98      0.97      0.97       300\n",
      "  weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = 'Status'\n",
    "le_target = LabelEncoder()\n",
    "y = le_target.fit_transform(df_train_final[target])\n",
    "X = df_train_final[features]\n",
    "mapping = dict(zip(le_target.transform(le_target.classes_), le_target.classes_))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, model.predict(X_test), target_names=le_target.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inference & Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risky Invoices Found: 10\n",
      "\n",
      "    Role: Accounts Payable Auditor.\n",
      "    Task: Explain the rejection risk concisely.\n",
      "\n",
      "    Invoice: INV-NEW-0014\n",
      "    Description: Software Development Consultation - Q3\n",
      "    Amount: 13372.7 USD\n",
      "    Supplier Risk: 91 (High is bad)\n",
      "    Approval History: 60%\n",
      "    Variance from PO: 60.0%\n",
      "    Match Type: Strict\n",
      "    Model Prediction: Reject (Conf: 1.00)\n",
      "\n",
      "    Output a 1-sentence 'Reason for Rejection/Review' for the UI card.\n",
      "    \n",
      "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-exp\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\n",
      "Please retry in 13.392855664s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 13\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Predict on New Data\n",
    "X_new = df_new_final[features]\n",
    "probs = model.predict_proba(X_new)\n",
    "preds = model.predict(X_new)\n",
    "\n",
    "df_new_final['Predicted_Status'] = [mapping[p] for p in preds]\n",
    "df_new_final['Confidence'] = [max(prob) for prob in probs]\n",
    "\n",
    "# Find Risky Items\n",
    "risky = df_new_final[df_new_final['Predicted_Status'].isin(['Reject', 'Review Further'])]\n",
    "print(\"Risky Invoices Found:\", len(risky))\n",
    "\n",
    "if not risky.empty:\n",
    "    sample = risky.iloc[0]\n",
    "    \n",
    "    # Construct Summary for Gemini\n",
    "    prompt = f\"\"\"\n",
    "    Role: Accounts Payable Auditor.\n",
    "    Task: Explain the rejection risk concisely.\n",
    "    \n",
    "    Invoice: {sample['Invoice_ID']}\n",
    "    Description: {sample['Description']}\n",
    "    Amount: {sample['Invoice_Amount']} {sample['Currency']}\n",
    "    Supplier Risk: {sample['Sup_Risk']} (High is bad)\n",
    "    Approval History: {sample['Sup_Approval_Rate']:.0%}\n",
    "    Variance from PO: {sample['Amt_Variance']:.1%}\n",
    "    Match Type: {sample['Match_Type']}\n",
    "    Model Prediction: {sample['Predicted_Status']} (Conf: {sample['Confidence']:.2f})\n",
    "    \n",
    "    Output a 1-sentence 'Reason for Rejection/Review' for the UI card.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(prompt)\n",
    "    if GEMINI_API_KEY:\n",
    "        model_gen = genai.GenerativeModel('gemini-2.5-flash')\n",
    "        try:\n",
    "            res = model_gen.generate_content(prompt)\n",
    "            print(\"\\n--- DECISION CARD EXPLANATION ---\")\n",
    "            print(res.text)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
